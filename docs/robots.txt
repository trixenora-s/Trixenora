# Trixenora SEO Robots File
# For more information, visit https://www.robotstxt.org/

User-agent: *
Allow: /

# Disallow crawling of sensitive paths
Disallow: /uploads/
Disallow: /admin/
Disallow: /.env

# Allow specific crawlers
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

# Sitemap location
Sitemap: https://trixenora-s.github.io/Trixenora/sitemap.xml

# Crawl-delay (in seconds)
Crawl-delay: 1
